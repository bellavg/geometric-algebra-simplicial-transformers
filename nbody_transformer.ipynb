{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Al4Uw1kidGd5",
    "outputId": "e2e15025-7666-40bc-a129-994dc0568071",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:34.223593Z",
     "start_time": "2024-05-14T09:07:34.219834Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"clifford-group-equivariant-neural-networks\")\n",
    "\n",
    "# os.chdir('/')\n",
    "# if not os.path.exists(\"/clifford-group-equivariant-neural-networks\"):\n",
    "#     !git clone https://github.com/DavidRuhe/clifford-group-equivariant-neural-networks.git\n",
    "\n",
    "# !git clone https://github.com/DavidRuhe/clifford-group-equivariant-neural-networks.git\n",
    "# !cd clifford-group-equivariant-neural-networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "djGNemajmc4Y",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.195434Z",
     "start_time": "2024-05-14T09:07:34.342328Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from algebra.cliffordalgebra import CliffordAlgebra\n",
    "from models.modules.linear import MVLinear\n",
    "from models.modules.gp import SteerableGeometricProductLayer\n",
    "from models.modules.mvlayernorm import MVLayerNorm\n",
    "from models.modules.mvsilu import MVSiLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CO55FRH4FBic",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.212913Z",
     "start_time": "2024-05-14T09:07:35.206515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the metric for 3D space (Euclidean)\n",
    "metric = [1, 1, 1]\n",
    "d = len(metric)\n",
    "\n",
    "# Initialize the Clifford Algebra for 3D\n",
    "clifford_algebra = CliffordAlgebra(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TAZRAi5F8rk"
   },
   "source": [
    "## DATAPOINTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZff-33JAdw1"
   },
   "source": [
    "Example 1 datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cvETnqcqBQm0",
    "outputId": "8b17bd3b-8a27-454a-b26a-b52bf0975ab3",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.217272Z",
     "start_time": "2024-05-14T09:07:35.213600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000, 1.0000, 2.0000, 3.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Example point (x, y, z) and charge (q)\n",
    "x, y, z, q = 1.0, 2.0, 3.0, 0.5\n",
    "\n",
    "# Embed the point into Clifford Algebra as a vector\n",
    "vector = torch.tensor([x, y, z])\n",
    "vector_in_clifford = clifford_algebra.embed_grade(vector, grade=1)\n",
    "# Include the charge as a scalar part of the algebra\n",
    "charge_in_clifford = clifford_algebra.embed_grade(torch.tensor([q]), grade=0)\n",
    "\n",
    "# Combine the vector and charge into a single multivector\n",
    "point_with_charge = vector_in_clifford + charge_in_clifford\n",
    "\n",
    "# The 'point_with_charge' now represents the 3D point and its charge in Clifford space\n",
    "print(point_with_charge)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMIuwJyEFatN"
   },
   "source": [
    "Example multiple datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JG0yrtpbBQ0z",
    "outputId": "6572e308-f115-4391-ad17-c9192045ce25",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.221820Z",
     "start_time": "2024-05-14T09:07:35.218444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5000,  1.0000,  2.0000,  3.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  4.0000,  5.0000,  6.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.5000,  7.0000,  8.0000,  9.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.0000, 10.0000, 11.0000, 12.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.5000, 13.0000, 14.0000, 15.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Define coordinates and charges for 5 samples\n",
    "# Coordinates are given as a (5, 3) tensor where each row is a point (x, y, z)\n",
    "coordinates = torch.tensor([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.0],\n",
    "    [10.0, 11.0, 12.0],\n",
    "    [13.0, 14.0, 15.0]\n",
    "])\n",
    "\n",
    "# Charges are given as a (5, 1) tensor where each row is a charge\n",
    "charges = torch.tensor([\n",
    "    [0.5],\n",
    "    [1.0],\n",
    "    [1.5],\n",
    "    [2.0],\n",
    "    [2.5]\n",
    "])\n",
    "\n",
    "# Embed the vectors (coordinates) into Clifford Algebra\n",
    "vectors_in_clifford = clifford_algebra.embed_grade(coordinates, grade=1)\n",
    "\n",
    "# Embed the charges as scalar parts of the algebra\n",
    "charges_in_clifford = clifford_algebra.embed_grade(charges, grade=0)\n",
    "\n",
    "# Combine the vectors and charges into single multivectors for each sample\n",
    "points_with_charge = vectors_in_clifford + charges_in_clifford\n",
    "\n",
    "# 'points_with_charge' now contains the 5 points each with a charge in Clifford space\n",
    "print(points_with_charge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EEazgmrFdzh"
   },
   "source": [
    "Example NBODY points, but all features added into 1 clifford vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_jeYPtWSf3ol",
    "outputId": "8002de35-cde3-4f62-8fd0-62dd610a0608",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.225696Z",
     "start_time": "2024-05-14T09:07:35.222507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9884, -0.8536, -1.9983,  3.2983,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.7161,  0.3965,  2.0751,  2.3322,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0808, -1.7179,  1.8577,  1.0985,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5275,  0.3335,  0.0614,  1.1787,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.1833,  0.5944,  0.7600, -0.4432,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([5, 8])\n"
     ]
    }
   ],
   "source": [
    "# Number of bodies\n",
    "N = 5  # Example for 5 bodies, can be any number\n",
    "\n",
    "# Define properties: positions, charges, velocities\n",
    "positions = torch.randn(N, 3)  # Random 3D positions\n",
    "charges = torch.randn(N, 1)    # Random charges\n",
    "velocities = torch.randn(N, 3) # Random 3D velocities\n",
    "\n",
    "# Embed the properties into Clifford Algebra\n",
    "positions_in_clifford = clifford_algebra.embed_grade(positions, grade=1)\n",
    "charges_in_clifford = clifford_algebra.embed_grade(charges, grade=0)\n",
    "velocities_in_clifford = clifford_algebra.embed_grade(velocities, grade=1)  # Also a vector\n",
    "\n",
    "# Combine all properties into a single multivector for each body\n",
    "bodies = positions_in_clifford + charges_in_clifford + velocities_in_clifford\n",
    "\n",
    "# 'bodies' now contains N multivectors, each representing a body with position, charge, and velocity\n",
    "print(bodies)\n",
    "print(bodies.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfKJnAH_RMpr"
   },
   "source": [
    "Example full with concat like in the code (seperate clifford vector for all features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJV47VB9PBl2",
    "outputId": "fa7e19b9-d627-455b-f027-826c448cb787",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.229577Z",
     "start_time": "2024-05-14T09:07:35.226345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invariants reshaped: torch.Size([5, 1, 8])\n",
      "Covariants: torch.Size([5, 2, 8])\n",
      "Concatenated input: torch.Size([5, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "# Number of bodies\n",
    "N = 5  # Example for 5 bodies, can be any number\n",
    "\n",
    "# Define properties: positions, charges, velocities\n",
    "positions = torch.randn(N, 3)  # Random 3D positions\n",
    "charges = torch.randn(N, 1)    # Random charges\n",
    "velocities = torch.randn(N, 3) # Random 3D velocities\n",
    "\n",
    "# Embed the properties into Clifford Algebra\n",
    "charges_in_clifford = clifford_algebra.embed_grade(charges, grade=0)\n",
    "\n",
    "# positions_in_clifford = clifford_algebra.embed_grade(positions, grade=1)\n",
    "# velocities_in_clifford = clifford_algebra.embed_grade(velocities, grade=1)  # Also a vector\n",
    "\n",
    "xv = torch.stack([positions, velocities], dim=1)\n",
    "embedded_xv = clifford_algebra.embed(xv, (1, 2, 3))\n",
    "\n",
    "bodies = torch.cat([charges_in_clifford[:, None], embedded_xv], dim=1)\n",
    "\n",
    "# (batch_size, feature_size) -> (batch_size, 1, feature_size). The None index is a shorthand for unsqueeze, which adds a singleton dimension at the specified index (here, index 1).\n",
    "print(\"Invariants reshaped:\", charges_in_clifford[:, None].shape)  # (5, 1, 8)\n",
    "print(\"Covariants:\", embedded_xv.shape)                    # (5, 2, 8)\n",
    "print(\"Concatenated input:\", bodies.shape)                 # (5, 3, 8)\n",
    "\n",
    "# 'bodies' now contains N multivectors, each a sample with with position, charge, and velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B1rqqeeF_wd"
   },
   "source": [
    "# EDGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xfiiq3GhGggt"
   },
   "source": [
    "Now lets look at the edges of the graph as defined above (N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bWi-lVAGY4L",
    "outputId": "546a97cd-0b0e-4db2-b6dc-e88d12336839",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.235073Z",
     "start_time": "2024-05-14T09:07:35.230139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges:\n",
      "tensor([[0, 1],\n",
      "        [0, 2],\n",
      "        [0, 3],\n",
      "        [0, 4],\n",
      "        [1, 2],\n",
      "        [1, 3],\n",
      "        [1, 4],\n",
      "        [2, 3],\n",
      "        [2, 4],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Edges and edge attributes\n",
    "# Assuming fully connected graph, every node to every other node\n",
    "edges = torch.combinations(torch.arange(N), r=2)\n",
    "\n",
    "print(\"Edges:\")\n",
    "print(edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoi5LcWlG3sm"
   },
   "source": [
    "Lets define the edge attributes for now, just take distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6qC9hpH1GY6w",
    "outputId": "1ba1c040-dc97-441a-803e-08a3524b932c",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.240141Z",
     "start_time": "2024-05-14T09:07:35.235737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Attributes (Distances):\n",
      "tensor([[2.6651, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.7239, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [3.8979, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [3.5068, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [2.5543, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.6960, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.3947, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [3.0491, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [3.0682, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.9414, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "torch.Size([10, 8])\n"
     ]
    }
   ],
   "source": [
    "distance = torch.norm(positions[edges[:, 0]] - positions[edges[:, 1]], dim=1).unsqueeze(1)\n",
    "edge_attr = clifford_algebra.embed_grade(distance, grade=0)  # Embedding distance as an edge attribute\n",
    "\n",
    "print(\"Edge Attributes (Distances):\")\n",
    "print(edge_attr)\n",
    "print(edge_attr.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNz8QJOpHQ4o"
   },
   "source": [
    "Now, lets imagine we do not have edge attributes, how would we calculate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vw4fpYloGY9l",
    "outputId": "5581853e-f520-4daa-d8ef-1d9929751fe4",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.244945Z",
     "start_time": "2024-05-14T09:07:35.240748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Attributes (Difference + Geom product):\n",
      "torch.Size([10, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "edge_attributes = []\n",
    "for edge in edges:\n",
    "    node1, node2 = edge\n",
    "\n",
    "    # difference between node features\n",
    "    node_i_features = bodies[node1]\n",
    "    node_j_features = bodies[node2]\n",
    "    difference = node_i_features - node_j_features\n",
    "\n",
    "    # geom product between node features\n",
    "    geom_product = clifford_algebra.geometric_product(node_i_features, node_j_features)\n",
    "\n",
    "    # now just add the 2 to get the \"representation of the edge\"\n",
    "    edge_attributes.append(difference + geom_product)\n",
    "\n",
    "edge_attributes = torch.stack(edge_attributes)  # Stack all edge attributes into a tensor\n",
    "\n",
    "print(\"Edge Attributes (Difference + Geom product):\")\n",
    "print(edge_attributes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPqbNgaYKvqe"
   },
   "source": [
    "Lets transform the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "P3AE9xlElgUh",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.249395Z",
     "start_time": "2024-05-14T09:07:35.247093Z"
    }
   },
   "outputs": [],
   "source": [
    "in_features = bodies.shape[1] # 3\n",
    "hidden_features = 2\n",
    "\n",
    "# SUBSPACES??!!\n",
    "node_to_hidden = MVLinear(clifford_algebra, in_features, hidden_features, subspaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZDFHv4RSvXm",
    "outputId": "f3baf6b8-ddca-4bcd-b6c0-74a3a4e390d9",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.256156Z",
     "start_time": "2024-05-14T09:07:35.250144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 8])\n"
     ]
    }
   ],
   "source": [
    "h_bodies = node_to_hidden(bodies)\n",
    "print(h_bodies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDngD9zlsOwL"
   },
   "source": [
    "And the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RqjWXAAEsJBB",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.259093Z",
     "start_time": "2024-05-14T09:07:35.256756Z"
    }
   },
   "outputs": [],
   "source": [
    "in_features = edge_attributes.shape[1] # 3\n",
    "hidden_features = 3\n",
    "\n",
    "# SUBSPACES??\n",
    "edge_to_hidden = MVLinear(clifford_algebra, in_features, hidden_features, subspaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btCsHsEzsRWh",
    "outputId": "0ae43020-e019-4474-e3bf-ed8fc20e12c2",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.262265Z",
     "start_time": "2024-05-14T09:07:35.260029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "h_edges = edge_to_hidden(edge_attributes)\n",
    "print(h_edges.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oYJ3qgUtHT6"
   },
   "source": [
    "## now that that is out of the way, lets create some functions to streamline everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LY2n82NF1Sgs",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.265084Z",
     "start_time": "2024-05-14T09:07:35.262766Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_edge_attr(node_features, edges, batch_size):\n",
    "    edge_attributes = []\n",
    "\n",
    "    total_number_edges = edges[0].shape[0]\n",
    "\n",
    "    # Loop over all edges\n",
    "    for i in range(total_number_edges):\n",
    "\n",
    "        node1 = edges[0][i]\n",
    "        node2 = edges[1][i]\n",
    "\n",
    "        # difference between node features\n",
    "        node_i_features = node_features[node1]  # [#features(charge, loc, vel), dim]\n",
    "        node_j_features = node_features[node2]  # [#features(charge, loc, vel), dim]\n",
    "        difference = node_i_features - node_j_features\n",
    "\n",
    "        # geom product between node features\n",
    "        geom_product = clifford_algebra.geometric_product(node_i_features, node_j_features)\n",
    "\n",
    "        # now just add the 2 to get the \"representation of the edge\"\n",
    "        # Stack all\n",
    "        edge_representation = torch.cat((difference, geom_product), dim=0)\n",
    "        edge_attributes.append(edge_representation)\n",
    "\n",
    "    edge_attributes = torch.stack(edge_attributes)\n",
    "    return edge_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3PsPP03ZtK3y",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.269475Z",
     "start_time": "2024-05-14T09:07:35.265743Z"
    }
   },
   "outputs": [],
   "source": [
    "def embed_nbody_graphs(batch):\n",
    "    loc, vel, edge_attr, charges, loc_end, edges = batch\n",
    "\n",
    "    batch_size, n_nodes, _ = loc.size()\n",
    "\n",
    "\n",
    "    # put the mean of the pointcloud on the origin (WHY?)\n",
    "    loc_mean = loc - loc.mean(dim=1, keepdim=True)     # [batch, nodes, dim]\n",
    "\n",
    "\n",
    "    # ALL THESE do [batch, nodes, dim] ->>> [batch * nodes, dim] BUT WHYYY\n",
    "    loc_mean = loc_mean.float().view(-1, *loc_mean.shape[2:])\n",
    "    loc = loc.float().view(-1, *loc.shape[2:])\n",
    "    vel = vel.float().view(-1, *vel.shape[2:])\n",
    "    edge_attr = edge_attr.float().view(-1, *edge_attr.shape[2:])\n",
    "    charges = charges.float().view(-1, *charges.shape[2:])\n",
    "    loc_end = loc_end.float().view(-1, *loc_end.shape[2:])\n",
    "\n",
    "    invariants = charges\n",
    "    invariants = clifford_algebra.embed(invariants, (0,))\n",
    "    charges_in_clifford = invariants\n",
    "\n",
    "    xv = torch.stack([loc_mean, vel], dim=1) # now of the shape [batch * nodes, 2 (because its loc mean as well as vel), dim]\n",
    "    covariants = clifford_algebra.embed(xv, (1, 2, 3))\n",
    "    pos_vel_in_clifford = covariants\n",
    "\n",
    "\n",
    "    # the [:, none] adds a dimension to invariants: [500, 8] to 500, 1, 8]) so they can be concatinated\n",
    "    nodes_in_clifford = torch.cat([invariants[:, None], covariants], dim=1) # [batch * nodes, #features(charge, loc, vel), dim]\n",
    "    # print('nodes_in_clifford: [batch * nodes, #features(charge, loc, vel), dim]', nodes_in_clifford.shape)\n",
    "\n",
    "    # till now: edges [batch, 2, n_nodes] so per batch, first row is starting nodes, second row is finishing nodes.\n",
    "    # Batch 1:  [[0, 1, 2, 3, 4],  # Start nodes\n",
    "    #            [1, 2, 3, 4, 0]]  # End nodes\n",
    "\n",
    "    # Batch 2:  [[0, 1, 2, 3, 4],  # Start nodes\n",
    "    #            [1, 2, 3, 4, 0]]  # End nodes\n",
    "\n",
    "    # Batch 3:  [[0, 1, 2, 3, 4],  # Start nodes\n",
    "    #            [1, 2, 3, 4, 0]]  # End nodes\n",
    "\n",
    "\n",
    "    # THEIR CODE, IDK IF NEEDED\n",
    "    batch_index = torch.arange(batch_size, device=loc_mean.device) # torch.arange(batch_size) generates a tensor from 0 to batch_size - 1, creating a sequence that represents each graph in the batch. If batch_size is 3, this tensor will be [0, 1, 2]\n",
    "    edges = edges + n_nodes * batch_index[:, None, None] # creates separate edge number for every graph. so if edge for graph 1 is between 3 and 4, graph 2 will be between 8 and 9 (if n_nodes = 5)\n",
    "    edges = tuple(edges.transpose(0, 1).flatten(1)) # where the first element of the tuple contains all start nodes and the second contains all end nodes for edges across the entire batch. ([edges*batch], [edges*batch])\n",
    "\n",
    "    extra_edge_attr_clifford = make_edge_attr(nodes_in_clifford, edges, batch_size) # [batch*edges, #numfeatures, difference + geomprod, dim]\n",
    "\n",
    "    orig_edge_attr_clifford = clifford_algebra.embed(edge_attr[..., None], (0,)) # now [batch * edges, 1, dim]\n",
    "\n",
    "    return nodes_in_clifford, extra_edge_attr_clifford, orig_edge_attr_clifford\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PiZr4WTX5_4y",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.273035Z",
     "start_time": "2024-05-14T09:07:35.270320Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_mock_batch(batch_size):\n",
    "    \"\"\"\n",
    "    Generate a mock batch of data with specified shapes.\n",
    "\n",
    "    Parameters:\n",
    "    - batch_size (int): The size of the batch to generate.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing tensors for loc_frame_0, vel_frame_0, edge_attr, charges, loc_frame_T, and edges.\n",
    "    \"\"\"\n",
    "    # Constants\n",
    "    n_nodes = 5  # Number of nodes\n",
    "    n_features = 3  # Number of spatial features (e.g., x, y, z)\n",
    "    n_edges = 20  # Number of edges\n",
    "    n_edge_features = 1  # Number of features per edge\n",
    "\n",
    "    # Generate data\n",
    "    loc_frame_0 = torch.rand(batch_size, n_nodes, n_features)\n",
    "    vel_frame_0 = torch.rand(batch_size, n_nodes, n_features)\n",
    "    edge_attr = torch.rand(batch_size, n_edges, n_edge_features)\n",
    "    charges = torch.rand(batch_size, n_nodes, 1)\n",
    "    loc_frame_T = torch.rand(batch_size, n_nodes, n_features)\n",
    "\n",
    "    # Generate edges indices\n",
    "    # For simplicity, assuming all batches share the same structure of graph\n",
    "    rows = torch.randint(0, n_nodes, (n_edges,))\n",
    "    cols = torch.randint(0, n_nodes, (n_edges,))\n",
    "    edges = torch.stack([rows, cols], dim=0).repeat(batch_size, 1, 1)  # Repeat the edge structure across the batch\n",
    "\n",
    "    return loc_frame_0, vel_frame_0, edge_attr, charges, loc_frame_T, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fnh-oBZBjPLh",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.276244Z",
     "start_time": "2024-05-14T09:07:35.273770Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example of using the function with a batch size of 69\n",
    "batch_size = 100\n",
    "data = generate_mock_batch(batch_size)\n",
    "# n_nodes = 5  # Number of nodes\n",
    "# n_features = 3  # Number of spatial features (e.g., x, y, z)\n",
    "# n_edges = 20  # Number of edges\n",
    "# n_edge_features = 1  # Number of features per edge\n",
    "\n",
    "# Print the shapes of each element in the data tuple\n",
    "data_shapes = [d.shape for d in data]\n",
    "# print(\"Shape of loc_frame_0:\", data_shapes[0])\n",
    "# print(\"Shape of vel_frame_0:\", data_shapes[1])\n",
    "# print(\"Shape of edge_attr:\", data_shapes[2])\n",
    "# print(\"Shape of charges:\", data_shapes[3])\n",
    "# print(\"Shape of loc_frame_T:\", data_shapes[4])\n",
    "# print(\"Shape of edges:\", data_shapes[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IosWbhgK69ET",
    "outputId": "ceb05131-7a01-4ea8-8fff-3a985872946b",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.352955Z",
     "start_time": "2024-05-14T09:07:35.276846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined: torch.Size([2500, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "components = embed_nbody_graphs(data)\n",
    "nodes_in_clifford, extra_edge_attr_clifford, orig_edge_attr_clifford = components\n",
    "edges_in_clifford = torch.cat((extra_edge_attr_clifford, orig_edge_attr_clifford), dim=1)\n",
    "\n",
    "# This MVLinear should be somewhere else! HOW DOES THIS WORK PRECICELY\n",
    "\n",
    "edge_to_node_shape = MVLinear(clifford_algebra, edges_in_clifford.shape[1] , nodes_in_clifford.shape[1], subspaces=True)\n",
    "\n",
    "fully_embedded_edges = edge_to_node_shape(edges_in_clifford)\n",
    "\n",
    "\n",
    "# Adding a binary feature\n",
    "# Nodes get a [1, 0] and edges get a [0, 1]\n",
    "node_marker = torch.zeros(500, 1, 8)\n",
    "edge_marker = torch.ones(2000, 1, 8)\n",
    "\n",
    "# Concatenate this new feature\n",
    "nodes_encoded = torch.cat((nodes_in_clifford, node_marker), dim=1)  # New shape [500, 4, 8]\n",
    "edges_encoded = torch.cat((fully_embedded_edges, edge_marker), dim=1)  # New shape [2000, 4, 8]\n",
    "\n",
    "# Reshape to split according to graphs\n",
    "nodes = nodes_encoded.view(100, 5, 4, 8)   # Shape [100, 5, 3, 9]\n",
    "edges = edges_encoded.view(100, 20, 4, 8)  # Shape [100, 20, 3, 9]\n",
    "\n",
    "# Initialize a list to hold the combined tensors for each graph\n",
    "combined = []\n",
    "\n",
    "# Concatenate nodes and edges for each graph\n",
    "for i in range(100):\n",
    "    combined_graph = torch.cat((nodes[i], edges[i]), dim=0)  # Shape [25, 4, 8]\n",
    "    combined.append(combined_graph)\n",
    "\n",
    "combined = torch.stack(combined, dim=0)  # Shape [100, 25, 4, 8]\n",
    "final_tensor = combined.view(2500, 4, 8)  # Shape [2500, 4, 8]\n",
    "\n",
    "print('combined:', final_tensor.shape)\n",
    "\n",
    "\n",
    "# print(final_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-C42MKe324X"
   },
   "source": [
    "code for learnable positional encodings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "q6dhu2Ew3XVv",
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.359445Z",
     "start_time": "2024-05-14T09:07:35.353977Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GeometricAlgebraAttention(nn.Module):\n",
    "    def __init__(self, algebra, features, heads=8):\n",
    "        super().__init__()\n",
    "        self.algebra = algebra\n",
    "        self.heads = heads\n",
    "        self.features_per_head = features // heads\n",
    "        \n",
    "        assert features % heads == 0, \"Features must be divisible by heads\"\n",
    "        \n",
    "        self.query = MVLinear(self.algebra, features, features)\n",
    "        self.key = MVLinear(self.algebra, features, features)\n",
    "        self.value = MVLinear(self.algebra, features, features)\n",
    "        \n",
    "        self.unifyheads = MVLinear(self.algebra, features, features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, f = x.size()\n",
    "        print(f\"Input size: {x.size()}\")\n",
    "\n",
    "        queries = self.query(x).view(b, t, self.heads, self.features_per_head)\n",
    "        print(f\"Queries size: {queries.size()}\")\n",
    "        keys = self.key(x).view(b, t, self.heads, self.features_per_head)\n",
    "        print(f\"Keys size: {keys.size()}\")\n",
    "        values = self.value(x).view(b, t, self.heads, self.features_per_head)\n",
    "        print(f\"Values size: {values.size()}\")\n",
    "        \n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        values = values.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        \n",
    "        scores = torch.matmul(queries, keys.transpose(1, 2)) / (self.features_per_head ** 0.5)\n",
    "        scores = F.softmax(scores, dim=2)\n",
    "        \n",
    "        combined = torch.matmul(scores, values)\n",
    "        combined = combined.view(b, self.heads, t, self.features_per_head).transpose(1, 2).contiguous()\n",
    "        combined = combined.view(b, t, f)\n",
    "        \n",
    "        return self.unifyheads(combined)\n",
    "\n",
    "class NBodyCGGNN(nn.Module):\n",
    "    def __init__(self, algebra, in_features, hidden_features, out_features, n_heads=8, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.algebra = algebra\n",
    "        self.embedding = MVLinear(self.algebra, in_features, hidden_features)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            GeometricAlgebraAttention(self.algebra, hidden_features, heads=n_heads)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.projection = MVLinear(self.algebra, hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return self.projection(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.365409Z",
     "start_time": "2024-05-14T09:07:35.360351Z"
    }
   },
   "outputs": [],
   "source": [
    "class GeometricAlgebraAttention(nn.Module):\n",
    "    def __init__(self, algebra, features, heads=8):\n",
    "        super().__init__()\n",
    "        self.algebra = algebra\n",
    "        self.heads = heads\n",
    "        self.features_per_head = features // heads\n",
    "        assert features % heads == 0, \"Features must be divisible by heads\"\n",
    "        \n",
    "        self.query = MVLinear(self.algebra, features, features)\n",
    "        self.key = MVLinear(self.algebra, features, features)\n",
    "        self.value = MVLinear(self.algebra, features, features)\n",
    "        \n",
    "        self.unifyheads = MVLinear(self.algebra, features, features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, f = x.size()\n",
    "        print(f\"Input size before MVLinear: {x.size()}\")  # Check input size\n",
    "\n",
    "        queries = self.query(x)\n",
    "        keys = self.key(x)\n",
    "        values = self.value(x)\n",
    "        print(f\"Output size from MVLinear (queries): {queries.size()}\")  # Check output size\n",
    "\n",
    "        queries = queries.view(b, t, self.heads, self.features_per_head)\n",
    "        keys = keys.view(b, t, self.heads, self.features_per_head)\n",
    "        values = values.view(b, t, self.heads, self.features_per_head)\n",
    "\n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        values = values.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        \n",
    "        scores = torch.matmul(queries, keys.transpose(1, 2)) / (self.features_per_head ** 0.5)\n",
    "        scores = F.softmax(scores, dim=2)\n",
    "        \n",
    "        combined = torch.matmul(scores, values)\n",
    "        combined = combined.view(b, self.heads, t, self.features_per_head).transpose(1, 2).contiguous()\n",
    "        combined = combined.view(b, t, f)\n",
    "        \n",
    "        return self.unifyheads(combined)\n",
    "        \n",
    "\n",
    "class NBodyCGGNN(nn.Module):\n",
    "    def __init__(self, algebra, in_features, hidden_features, out_features, n_heads=8, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.algebra = algebra\n",
    "        self.embedding = MVLinear(self.algebra, in_features, hidden_features)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            GeometricAlgebraAttention(self.algebra, hidden_features, heads=n_heads)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.projection = MVLinear(self.algebra, hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return self.projection(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 6)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 145\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(batch_size):\n\u001B[1;32m    143\u001B[0m     batch \u001B[38;5;241m=\u001B[39m data[i]  \u001B[38;5;66;03m# Assuming data is a list of batches\u001B[39;00m\n\u001B[0;32m--> 145\u001B[0m     loc, vel, edge_attr, charges, loc_end, edges \u001B[38;5;241m=\u001B[39m batch\n\u001B[1;32m    147\u001B[0m     \u001B[38;5;66;03m# Prepare the input features\u001B[39;00m\n\u001B[1;32m    148\u001B[0m     nodes_in_clifford, extra_edge_attr_clifford, orig_edge_attr_clifford \u001B[38;5;241m=\u001B[39m embed_nbody_graphs(batch)\n",
      "\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 6)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming the necessary components are defined as follows:\n",
    "from algebra.cliffordalgebra import CliffordAlgebra\n",
    "from models.modules.linear import MVLinear\n",
    "\n",
    "class GeometricAlgebraAttention(nn.Module):\n",
    "    def __init__(self, algebra, features, heads=8):\n",
    "        super().__init__()\n",
    "        self.algebra = algebra\n",
    "        self.heads = heads\n",
    "        self.features_per_head = features // heads\n",
    "\n",
    "        self.query = MVLinear(self.algebra, features, features)\n",
    "        self.key = MVLinear(self.algebra, features, features)\n",
    "        self.value = MVLinear(self.algebra, features, features)\n",
    "\n",
    "        self.unifyheads = MVLinear(self.algebra, features, features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, f = x.size()\n",
    "\n",
    "        queries = self.query(x).view(b, t, self.heads, self.features_per_head)\n",
    "        keys = self.key(x).view(b, t, self.heads, self.features_per_head)\n",
    "        values = self.value(x).view(b, t, self.heads, self.features_per_head)\n",
    "\n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        values = values.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "\n",
    "        scores = torch.matmul(queries, keys.transpose(1, 2)) / (self.features_per_head ** 0.5)\n",
    "        scores = F.softmax(scores, dim=2)\n",
    "\n",
    "        combined = torch.matmul(scores, values)\n",
    "        combined = combined.view(b, self.heads, t, self.features_per_head).transpose(1, 2).contiguous()\n",
    "        combined = combined.view(b, t, f)\n",
    "\n",
    "        return self.unifyheads(combined)\n",
    "\n",
    "class NBodyGAT(nn.Module):\n",
    "    def __init__(self, algebra, in_features, hidden_features, out_features, n_heads=8, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.algebra = algebra\n",
    "        self.embedding = MVLinear(self.algebra, in_features, hidden_features)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            GeometricAlgebraAttention(self.algebra, hidden_features, heads=n_heads)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        self.projection = MVLinear(self.algebra, hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return self.projection(x)\n",
    "\n",
    "def embed_nbody_graphs(batch):\n",
    "    loc, vel, edge_attr, charges, loc_end, edges = batch\n",
    "\n",
    "    batch_size, n_nodes, _ = loc.size()\n",
    "\n",
    "    loc_mean = loc - loc.mean(dim=1, keepdim=True)     # [batch, nodes, dim]\n",
    "\n",
    "    loc_mean = loc_mean.float().view(-1, *loc_mean.shape[2:])\n",
    "    loc = loc.float().view(-1, *loc.shape[2:])\n",
    "    vel = vel.float().view(-1, *vel.shape[2:])\n",
    "    edge_attr = edge_attr.float().view(-1, *edge_attr.shape[2:])\n",
    "    charges = charges.float().view(-1, *charges.shape[2:])\n",
    "    loc_end = loc_end.float().view(-1, *loc_end.shape[2:])\n",
    "\n",
    "    invariants = charges\n",
    "    invariants = clifford_algebra.embed(invariants, (0,))\n",
    "    charges_in_clifford = invariants\n",
    "\n",
    "    xv = torch.stack([loc_mean, vel], dim=1)\n",
    "    covariants = clifford_algebra.embed(xv, (1, 2, 3))\n",
    "    pos_vel_in_clifford = covariants\n",
    "\n",
    "    nodes_in_clifford = torch.cat([invariants[:, None], covariants], dim=1)\n",
    "\n",
    "    batch_index = torch.arange(batch_size, device=loc_mean.device)\n",
    "    edges = edges + n_nodes * batch_index[:, None, None]\n",
    "    edges = tuple(edges.transpose(0, 1).flatten(1))\n",
    "\n",
    "    edge_attributes = []\n",
    "    for i in range(edges[0].shape[0]):\n",
    "        node1 = edges[0][i]\n",
    "        node2 = edges[1][i]\n",
    "        node_i_features = nodes_in_clifford[node1]\n",
    "        node_j_features = nodes_in_clifford[node2]\n",
    "        difference = node_i_features - node_j_features\n",
    "        geom_product = clifford_algebra.geometric_product(node_i_features, node_j_features)\n",
    "        edge_representation = torch.cat((difference, geom_product), dim=0)\n",
    "        edge_attributes.append(edge_representation)\n",
    "\n",
    "    extra_edge_attr_clifford = torch.stack(edge_attributes)\n",
    "    orig_edge_attr_clifford = clifford_algebra.embed(edge_attr[..., None], (0,))\n",
    "\n",
    "    return nodes_in_clifford, extra_edge_attr_clifford, orig_edge_attr_clifford\n",
    "\n",
    "def generate_mock_batch(batch_size):\n",
    "    n_nodes = 5\n",
    "    n_features = 3\n",
    "    n_edges = 20\n",
    "    n_edge_features = 1\n",
    "\n",
    "    loc_frame_0 = torch.rand(batch_size, n_nodes, n_features)\n",
    "    vel_frame_0 = torch.rand(batch_size, n_nodes, n_features)\n",
    "    edge_attr = torch.rand(batch_size, n_edges, n_edge_features)\n",
    "    charges = torch.rand(batch_size, n_nodes, 1)\n",
    "    loc_frame_T = torch.rand(batch_size, n_nodes, n_features)\n",
    "\n",
    "    rows = torch.randint(0, n_nodes, (n_edges,))\n",
    "    cols = torch.randint(0, n_nodes, (n_edges,))\n",
    "    edges = torch.stack([rows, cols], dim=0).repeat(batch_size, 1, 1)\n",
    "\n",
    "    return loc_frame_0, vel_frame_0, edge_attr, charges, loc_frame_T, edges\n",
    "\n",
    "# Generate mock data\n",
    "batch_size = 100\n",
    "data = generate_mock_batch(batch_size)\n",
    "num_epochs = 10\n",
    "\n",
    "# Initialize the Clifford Algebra and model\n",
    "clifford_algebra = CliffordAlgebra((1.0, 1.0, 1.0))\n",
    "model = NBodyGAT(clifford_algebra, in_features=4, hidden_features=8, out_features=1)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    epoch_loss = 0\n",
    "    for i in range(batch_size):\n",
    "        batch = data[i]  # Assuming data is a list of batches\n",
    "\n",
    "        loc, vel, edge_attr, charges, loc_end, edges = batch\n",
    "\n",
    "        # Prepare the input features\n",
    "        nodes_in_clifford, extra_edge_attr_clifford, orig_edge_attr_clifford = embed_nbody_graphs(batch)\n",
    "        edges_in_clifford = torch.cat((extra_edge_attr_clifford, orig_edge_attr_clifford), dim=1)\n",
    "\n",
    "        edge_to_node_shape = MVLinear(clifford_algebra, edges_in_clifford.shape[1], nodes_in_clifford.shape[1], subspaces=True)\n",
    "        fully_embedded_edges = edge_to_node_shape(edges_in_clifford)\n",
    "\n",
    "        # Adding a binary feature\n",
    "        node_marker = torch.zeros(nodes_in_clifford.size(0), 1, nodes_in_clifford.size(2))\n",
    "        edge_marker = torch.ones(fully_embedded_edges.size(0), 1, fully_embedded_edges.size(2))\n",
    "\n",
    "        # Concatenate this new feature\n",
    "        nodes_encoded = torch.cat((nodes_in_clifford, node_marker), dim=1)\n",
    "        edges_encoded = torch.cat((fully_embedded_edges, edge_marker), dim=1)\n",
    "\n",
    "        # Reshape to split according to graphs\n",
    "        nodes = nodes_encoded.view(batch_size, 5, 4, 8)\n",
    "        edges = edges_encoded.view(batch_size, 20, 4, 8)\n",
    "\n",
    "        combined = []\n",
    "        for j in range(batch_size):\n",
    "            combined_graph = torch.cat((nodes[j], edges[j]), dim=0)\n",
    "            combined.append(combined_graph)\n",
    "\n",
    "        combined = torch.stack(combined, dim=0)\n",
    "        final_tensor = combined.view(-1, 4, 8)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(final_tensor)\n",
    "\n",
    "        # Assuming targets are in loc_end\n",
    "        targets = loc_end.view(-1, 1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, targets)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss for reporting\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/batch_size}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'nbody_model.pth')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.989583Z",
     "start_time": "2024-05-14T09:07:35.366197Z"
    }
   },
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming the necessary components are defined as follows:\n",
    "from algebra.cliffordalgebra import CliffordAlgebra\n",
    "from models.modules.linear import MVLinear\n",
    "\n",
    "class GeometricAlgebraAttention(nn.Module):\n",
    "    def __init__(self, algebra, features, heads=8):\n",
    "        super().__init__()\n",
    "        self.algebra = algebra\n",
    "        self.heads = heads\n",
    "        self.features_per_head = features // heads\n",
    "\n",
    "        self.query = MVLinear(self.algebra, features, features)\n",
    "        self.key = MVLinear(self.algebra, features, features)\n",
    "        self.value = MVLinear(self.algebra, features, features)\n",
    "\n",
    "        self.unifyheads = MVLinear(self.algebra, features, features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, f = x.size()\n",
    "\n",
    "        queries = self.query(x).view(b, t, self.heads, self.features_per_head)\n",
    "        keys = self.key(x).view(b, t, self.heads, self.features_per_head)\n",
    "        values = self.value(x).view(b, t, self.heads, self.features_per_head)\n",
    "\n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        values = values.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "\n",
    "        scores = torch.matmul(queries, keys.transpose(1, 2)) / (self.features_per_head ** 0.5)\n",
    "        scores = F.softmax(scores, dim=2)\n",
    "\n",
    "        combined = torch.matmul(scores, values)\n",
    "        combined = combined.view(b, self.heads, t, self.features_per_head).transpose(1, 2).contiguous()\n",
    "        combined = combined.view(b, t, f)\n",
    "\n",
    "        return self.unifyheads(combined)\n",
    "\n",
    "class NBodyGAT(nn.Module):\n",
    "    def __init__(self, algebra, in_features, hidden_features, out_features, n_heads=8, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.algebra = algebra\n",
    "        self.embedding = MVLinear(self.algebra, in_features, hidden_features)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            GeometricAlgebraAttention(self.algebra, hidden_features, heads=n_heads)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        self.projection = MVLinear(self.algebra, hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return self.projection(x)\n",
    "\n",
    "def embed_nbody_graphs(batch):\n",
    "    loc, vel, edge_attr, charges, loc_end, edges = batch\n",
    "\n",
    "    batch_size, n_nodes, _ = loc.size()\n",
    "\n",
    "    loc_mean = loc - loc.mean(dim=1, keepdim=True)     # [batch, nodes, dim]\n",
    "\n",
    "    loc_mean = loc_mean.float().view(-1, *loc_mean.shape[2:])\n",
    "    loc = loc.float().view(-1, *loc.shape[2:])\n",
    "    vel = vel.float().view(-1, *vel.shape[2:])\n",
    "    edge_attr = edge_attr.float().view(-1, *edge_attr.shape[2:])\n",
    "    charges = charges.float().view(-1, *charges.shape[2:])\n",
    "    loc_end = loc_end.float().view(-1, *loc_end.shape[2:])\n",
    "\n",
    "    invariants = charges\n",
    "    invariants = clifford_algebra.embed(invariants, (0,))\n",
    "    charges_in_clifford = invariants\n",
    "\n",
    "    xv = torch.stack([loc_mean, vel], dim=1)\n",
    "    covariants = clifford_algebra.embed(xv, (1, 2, 3))\n",
    "    pos_vel_in_clifford = covariants\n",
    "\n",
    "    nodes_in_clifford = torch.cat([invariants[:, None], covariants], dim=1)\n",
    "\n",
    "    batch_index = torch.arange(batch_size, device=loc_mean.device)\n",
    "    edges = edges + n_nodes * batch_index[:, None, None]\n",
    "    edges = tuple(edges.transpose(0, 1).flatten(1))\n",
    "\n",
    "    edge_attributes = []\n",
    "    for i in range(edges[0].shape[0]):\n",
    "        node1 = edges[0][i]\n",
    "        node2 = edges[1][i]\n",
    "        node_i_features = nodes_in_clifford[node1]\n",
    "        node_j_features = nodes_in_clifford[node2]\n",
    "        difference = node_i_features - node_j_features\n",
    "        geom_product = clifford_algebra.geometric_product(node_i_features, node_j_features)\n",
    "        edge_representation = torch.cat((difference, geom_product), dim=0)\n",
    "        edge_attributes.append(edge_representation)\n",
    "\n",
    "    extra_edge_attr_clifford = torch.stack(edge_attributes)\n",
    "    orig_edge_attr_clifford = clifford_algebra.embed(edge_attr[..., None], (0,))\n",
    "\n",
    "    return nodes_in_clifford, extra_edge_attr_clifford, orig_edge_attr_clifford\n",
    "\n",
    "def generate_mock_batch(batch_size):\n",
    "    n_nodes = 5\n",
    "    n_features = 3\n",
    "    n_edges = 20\n",
    "    n_edge_features = 1\n",
    "\n",
    "    loc_frame_0 = torch.rand(batch_size, n_nodes, n_features)\n",
    "    vel_frame_0 = torch.rand(batch_size, n_nodes, n_features)\n",
    "    edge_attr = torch.rand(batch_size, n_edges, n_edge_features)\n",
    "    charges = torch.rand(batch_size, n_nodes, 1)\n",
    "    loc_frame_T = torch.rand(batch_size, n_nodes, n_features)\n",
    "\n",
    "    rows = torch.randint(0, n_nodes, (n_edges,))\n",
    "    cols = torch.randint(0, n_nodes, (n_edges,))\n",
    "    edges = torch.stack([rows, cols], dim=0).repeat(batch_size, 1, 1)\n",
    "\n",
    "    return loc_frame_0, vel_frame_0, edge_attr, charges, loc_frame_T, edges\n",
    "\n",
    "# Generate mock data\n",
    "batch_size = 100\n",
    "data = generate_mock_batch(batch_size)\n",
    "num_epochs = 10\n",
    "\n",
    "# Initialize the Clifford Algebra and model\n",
    "clifford_algebra = CliffordAlgebra((1.0, 1.0, 1.0))\n",
    "model = NBodyGAT(clifford_algebra, in_features=4, hidden_features=8, out_features=1)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Check the structure of the data\n",
    "for i, batch in enumerate(data):\n",
    "    print(f\"Batch {i}: {type(batch)}, shape: {batch.shape if isinstance(batch, torch.Tensor) else 'Not a tensor'}\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    # Prepare the input features from the data\n",
    "    loc, vel, edge_attr, charges, loc_end, edges = data\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        batch = (loc[i], vel[i], edge_attr[i], charges[i], loc_end[i], edges[:, :, i])  # Extract batch data\n",
    "\n",
    "        # Unpack batch\n",
    "        loc, vel, edge_attr, charges, loc_end, edges = batch\n",
    "\n",
    "        nodes_in_clifford, extra_edge_attr_clifford, orig_edge_attr_clifford = embed_nbody_graphs(batch)\n",
    "        edges_in_clifford = torch.cat((extra_edge_attr_clifford, orig_edge_attr_clifford), dim=1)\n",
    "\n",
    "        edge_to_node_shape = MVLinear(clifford_algebra, edges_in_clifford.shape[1], nodes_in_clifford.shape[1], subspaces=True)\n",
    "        fully_embedded_edges = edge_to_node_shape(edges_in_clifford)\n",
    "\n",
    "        # Adding a binary feature\n",
    "        node_marker = torch.zeros(nodes_in_clifford.size(0), 1, nodes_in_clifford.size(2))\n",
    "        edge_marker = torch.ones(fully_embedded_edges.size(0), 1, fully_embedded_edges.size(2))\n",
    "\n",
    "        # Concatenate this new feature\n",
    "        nodes_encoded = torch.cat((nodes_in_clifford, node_marker), dim=1)\n",
    "        edges_encoded = torch.cat((fully_embedded_edges, edge_marker), dim=1)\n",
    "\n",
    "        # Reshape to split according to graphs\n",
    "        nodes = nodes_encoded.view(batch_size, 5, 4, 8)\n",
    "        edges = edges_encoded.view(batch_size, 20, 4, 8)\n",
    "\n",
    "        combined = []\n",
    "        for j in range(batch_size):\n",
    "            combined_graph = torch.cat((nodes[j], edges[j]), dim=0)\n",
    "            combined.append(combined_graph)\n",
    "\n",
    "        combined = torch.stack(combined, dim=0)\n",
    "        final_tensor = combined.view(-1, 4, 8)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(final_tensor)\n",
    "\n",
    "        # Assuming targets are in loc_end\n",
    "        targets = loc_end.view(-1, 1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, targets)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss for reporting\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/batch_size}')\n",
    "\n",
    "# Save the\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.990406Z",
     "start_time": "2024-05-14T09:07:35.990359Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:07:35.991189Z",
     "start_time": "2024-05-14T09:07:35.991050Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NBodyCGGNN(clifford_algebra, in_features=4, hidden_features=8, out_features=1)  # Example with hidden_features=8\n",
    "final_tensor_reshaped = final_tensor.view(-1, 4, 8)  # Ensure it matches the total elements\n",
    "output = model(final_tensor_reshaped)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clifford_algebra = CliffordAlgebra((1.0, 1.0, 1.0))\n",
    "model = NBodyCGGNN(clifford_algebra, in_features=4, hidden_features=32, out_features=1)  # Changed hidden_features to 32\n",
    "final_tensor_reshaped = final_tensor.view(-1, 4, 8)\n",
    "output = model(final_tensor_reshaped)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = NBodyCGGNN(clifford_algebra, in_features=4, hidden_features=8, out_features=1)  # Example with hidden_features=8\n",
    "final_tensor_reshaped = final_tensor.view(-1, 4, 8)  # Ensure it matches the total elements\n",
    "output = model(final_tensor_reshaped)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
