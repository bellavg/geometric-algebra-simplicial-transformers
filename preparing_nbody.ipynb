{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Al4Uw1kidGd5",
    "outputId": "e2e15025-7666-40bc-a129-994dc0568071",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:41.595856Z",
     "start_time": "2024-05-14T08:10:41.592317Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"clifford-group-equivariant-neural-networks\")\n",
    "\n",
    "# os.chdir('/')\n",
    "# if not os.path.exists(\"/clifford-group-equivariant-neural-networks\"):\n",
    "#     !git clone https://github.com/DavidRuhe/clifford-group-equivariant-neural-networks.git\n",
    "\n",
    "# !git clone https://github.com/DavidRuhe/clifford-group-equivariant-neural-networks.git\n",
    "# !cd clifford-group-equivariant-neural-networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "djGNemajmc4Y",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.662015Z",
     "start_time": "2024-05-14T08:10:41.633388Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from algebra.cliffordalgebra import CliffordAlgebra\n",
    "from models.modules.linear import MVLinear\n",
    "from models.modules.gp import SteerableGeometricProductLayer\n",
    "from models.modules.mvlayernorm import MVLayerNorm\n",
    "from models.modules.mvsilu import MVSiLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CO55FRH4FBic",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.712567Z",
     "start_time": "2024-05-14T08:10:42.684902Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the metric for 3D space (Euclidean)\n",
    "metric = [1, 1, 1]\n",
    "d = len(metric)\n",
    "\n",
    "# Initialize the Clifford Algebra for 3D\n",
    "clifford_algebra = CliffordAlgebra(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TAZRAi5F8rk"
   },
   "source": [
    "## DATAPOINTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZff-33JAdw1"
   },
   "source": [
    "Example 1 datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cvETnqcqBQm0",
    "outputId": "8b17bd3b-8a27-454a-b26a-b52bf0975ab3",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.722132Z",
     "start_time": "2024-05-14T08:10:42.713307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000, 1.0000, 2.0000, 3.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Example point (x, y, z) and charge (q)\n",
    "x, y, z, q = 1.0, 2.0, 3.0, 0.5\n",
    "\n",
    "# Embed the point into Clifford Algebra as a vector\n",
    "vector = torch.tensor([x, y, z])\n",
    "vector_in_clifford = clifford_algebra.embed_grade(vector, grade=1)\n",
    "# Include the charge as a scalar part of the algebra\n",
    "charge_in_clifford = clifford_algebra.embed_grade(torch.tensor([q]), grade=0)\n",
    "\n",
    "# Combine the vector and charge into a single multivector\n",
    "point_with_charge = vector_in_clifford + charge_in_clifford\n",
    "\n",
    "# The 'point_with_charge' now represents the 3D point and its charge in Clifford space\n",
    "print(point_with_charge)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMIuwJyEFatN"
   },
   "source": [
    "Example multiple datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JG0yrtpbBQ0z",
    "outputId": "6572e308-f115-4391-ad17-c9192045ce25",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.726416Z",
     "start_time": "2024-05-14T08:10:42.723356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5000,  1.0000,  2.0000,  3.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  4.0000,  5.0000,  6.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.5000,  7.0000,  8.0000,  9.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.0000, 10.0000, 11.0000, 12.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.5000, 13.0000, 14.0000, 15.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Define coordinates and charges for 5 samples\n",
    "# Coordinates are given as a (5, 3) tensor where each row is a point (x, y, z)\n",
    "coordinates = torch.tensor([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.0],\n",
    "    [10.0, 11.0, 12.0],\n",
    "    [13.0, 14.0, 15.0]\n",
    "])\n",
    "\n",
    "# Charges are given as a (5, 1) tensor where each row is a charge\n",
    "charges = torch.tensor([\n",
    "    [0.5],\n",
    "    [1.0],\n",
    "    [1.5],\n",
    "    [2.0],\n",
    "    [2.5]\n",
    "])\n",
    "\n",
    "# Embed the vectors (coordinates) into Clifford Algebra\n",
    "vectors_in_clifford = clifford_algebra.embed_grade(coordinates, grade=1)\n",
    "\n",
    "# Embed the charges as scalar parts of the algebra\n",
    "charges_in_clifford = clifford_algebra.embed_grade(charges, grade=0)\n",
    "\n",
    "# Combine the vectors and charges into single multivectors for each sample\n",
    "points_with_charge = vectors_in_clifford + charges_in_clifford\n",
    "\n",
    "# 'points_with_charge' now contains the 5 points each with a charge in Clifford space\n",
    "print(points_with_charge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EEazgmrFdzh"
   },
   "source": [
    "Example NBODY points, but all features added into 1 clifford vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_jeYPtWSf3ol",
    "outputId": "8002de35-cde3-4f62-8fd0-62dd610a0608",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.730561Z",
     "start_time": "2024-05-14T08:10:42.726965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5332,  3.7511, -0.6442, -0.0994,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.0938, -0.9998, -1.2155, -0.2917,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1901,  0.9404,  0.5315,  2.2506,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.3886,  0.7503, -1.7671,  0.0770,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.0725,  0.2362, -0.7514, -0.0230,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([5, 8])\n"
     ]
    }
   ],
   "source": [
    "# Number of bodies\n",
    "N = 5  # Example for 5 bodies, can be any number\n",
    "\n",
    "# Define properties: positions, charges, velocities\n",
    "positions = torch.randn(N, 3)  # Random 3D positions\n",
    "charges = torch.randn(N, 1)    # Random charges\n",
    "velocities = torch.randn(N, 3) # Random 3D velocities\n",
    "\n",
    "# Embed the properties into Clifford Algebra\n",
    "positions_in_clifford = clifford_algebra.embed_grade(positions, grade=1)\n",
    "charges_in_clifford = clifford_algebra.embed_grade(charges, grade=0)\n",
    "velocities_in_clifford = clifford_algebra.embed_grade(velocities, grade=1)  # Also a vector\n",
    "\n",
    "# Combine all properties into a single multivector for each body\n",
    "bodies = positions_in_clifford + charges_in_clifford + velocities_in_clifford\n",
    "\n",
    "# 'bodies' now contains N multivectors, each representing a body with position, charge, and velocity\n",
    "print(bodies)\n",
    "print(bodies.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfKJnAH_RMpr"
   },
   "source": [
    "Example full with concat like in the code (seperate clifford vector for all features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJV47VB9PBl2",
    "outputId": "fa7e19b9-d627-455b-f027-826c448cb787",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.737448Z",
     "start_time": "2024-05-14T08:10:42.731139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invariants reshaped: torch.Size([5, 1, 8])\n",
      "Covariants: torch.Size([5, 2, 8])\n",
      "Concatenated input: torch.Size([5, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "# Number of bodies\n",
    "N = 5  # Example for 5 bodies, can be any number\n",
    "\n",
    "# Define properties: positions, charges, velocities\n",
    "positions = torch.randn(N, 3)  # Random 3D positions\n",
    "charges = torch.randn(N, 1)    # Random charges\n",
    "velocities = torch.randn(N, 3) # Random 3D velocities\n",
    "\n",
    "# Embed the properties into Clifford Algebra\n",
    "charges_in_clifford = clifford_algebra.embed_grade(charges, grade=0)\n",
    "\n",
    "# positions_in_clifford = clifford_algebra.embed_grade(positions, grade=1)\n",
    "# velocities_in_clifford = clifford_algebra.embed_grade(velocities, grade=1)  # Also a vector\n",
    "\n",
    "xv = torch.stack([positions, velocities], dim=1)\n",
    "embedded_xv = clifford_algebra.embed(xv, (1, 2, 3))\n",
    "\n",
    "bodies = torch.cat([charges_in_clifford[:, None], embedded_xv], dim=1)\n",
    "\n",
    "# (batch_size, feature_size) -> (batch_size, 1, feature_size). The None index is a shorthand for unsqueeze, which adds a singleton dimension at the specified index (here, index 1).\n",
    "print(\"Invariants reshaped:\", charges_in_clifford[:, None].shape)  # (5, 1, 8)\n",
    "print(\"Covariants:\", embedded_xv.shape)                    # (5, 2, 8)\n",
    "print(\"Concatenated input:\", bodies.shape)                 # (5, 3, 8)\n",
    "\n",
    "# 'bodies' now contains N multivectors, each a sample with with position, charge, and velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B1rqqeeF_wd"
   },
   "source": [
    "# EDGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xfiiq3GhGggt"
   },
   "source": [
    "Now lets look at the edges of the graph as defined above (N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bWi-lVAGY4L",
    "outputId": "546a97cd-0b0e-4db2-b6dc-e88d12336839",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.744416Z",
     "start_time": "2024-05-14T08:10:42.738068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges:\n",
      "tensor([[0, 1],\n",
      "        [0, 2],\n",
      "        [0, 3],\n",
      "        [0, 4],\n",
      "        [1, 2],\n",
      "        [1, 3],\n",
      "        [1, 4],\n",
      "        [2, 3],\n",
      "        [2, 4],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Edges and edge attributes\n",
    "# Assuming fully connected graph, every node to every other node\n",
    "edges = torch.combinations(torch.arange(N), r=2)\n",
    "\n",
    "print(\"Edges:\")\n",
    "print(edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoi5LcWlG3sm"
   },
   "source": [
    "Lets define the edge attributes for now, just take distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6qC9hpH1GY6w",
    "outputId": "1ba1c040-dc97-441a-803e-08a3524b932c",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.751097Z",
     "start_time": "2024-05-14T08:10:42.745155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Attributes (Distances):\n",
      "tensor([[2.5804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.2179, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.9496, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [2.7965, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.4577, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [2.7001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [2.4782, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.9803, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [2.0263, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [2.4883, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "torch.Size([10, 8])\n"
     ]
    }
   ],
   "source": [
    "distance = torch.norm(positions[edges[:, 0]] - positions[edges[:, 1]], dim=1).unsqueeze(1)\n",
    "edge_attr = clifford_algebra.embed_grade(distance, grade=0)  # Embedding distance as an edge attribute\n",
    "\n",
    "print(\"Edge Attributes (Distances):\")\n",
    "print(edge_attr)\n",
    "print(edge_attr.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNz8QJOpHQ4o"
   },
   "source": [
    "Now, lets imagine we do not have edge attributes, how would we calculate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vw4fpYloGY9l",
    "outputId": "5581853e-f520-4daa-d8ef-1d9929751fe4",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.756460Z",
     "start_time": "2024-05-14T08:10:42.751618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Attributes (Difference + Geom product):\n",
      "torch.Size([10, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "edge_attributes = []\n",
    "for edge in edges:\n",
    "    node1, node2 = edge\n",
    "\n",
    "    # difference between node features\n",
    "    node_i_features = bodies[node1]\n",
    "    node_j_features = bodies[node2]\n",
    "    difference = node_i_features - node_j_features\n",
    "\n",
    "    # geom product between node features\n",
    "    geom_product = clifford_algebra.geometric_product(node_i_features, node_j_features)\n",
    "\n",
    "    # now just add the 2 to get the \"representation of the edge\"\n",
    "    edge_attributes.append(difference + geom_product)\n",
    "\n",
    "edge_attributes = torch.stack(edge_attributes)  # Stack all edge attributes into a tensor\n",
    "\n",
    "print(\"Edge Attributes (Difference + Geom product):\")\n",
    "print(edge_attributes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPqbNgaYKvqe"
   },
   "source": [
    "Lets transform the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "P3AE9xlElgUh",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.760078Z",
     "start_time": "2024-05-14T08:10:42.758270Z"
    }
   },
   "outputs": [],
   "source": [
    "in_features = bodies.shape[1] # 3\n",
    "hidden_features = 2\n",
    "\n",
    "# SUBSPACES??!!\n",
    "node_to_hidden = MVLinear(clifford_algebra, in_features, hidden_features, subspaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZDFHv4RSvXm",
    "outputId": "f3baf6b8-ddca-4bcd-b6c0-74a3a4e390d9",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.766193Z",
     "start_time": "2024-05-14T08:10:42.760735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 8])\n"
     ]
    }
   ],
   "source": [
    "h_bodies = node_to_hidden(bodies)\n",
    "print(h_bodies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDngD9zlsOwL"
   },
   "source": [
    "And the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RqjWXAAEsJBB",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.768958Z",
     "start_time": "2024-05-14T08:10:42.767092Z"
    }
   },
   "outputs": [],
   "source": [
    "in_features = edge_attributes.shape[1] # 3\n",
    "hidden_features = 3\n",
    "\n",
    "# SUBSPACES??\n",
    "edge_to_hidden = MVLinear(clifford_algebra, in_features, hidden_features, subspaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btCsHsEzsRWh",
    "outputId": "0ae43020-e019-4474-e3bf-ed8fc20e12c2",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.771299Z",
     "start_time": "2024-05-14T08:10:42.769418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "h_edges = edge_to_hidden(edge_attributes)\n",
    "print(h_edges.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oYJ3qgUtHT6"
   },
   "source": [
    "## now that that is out of the way, lets create some functions to streamline everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LY2n82NF1Sgs",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.773912Z",
     "start_time": "2024-05-14T08:10:42.771873Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_edge_attr(node_features, edges, batch_size):\n",
    "    edge_attributes = []\n",
    "\n",
    "    total_number_edges = edges[0].shape[0]\n",
    "\n",
    "    # Loop over all edges\n",
    "    for i in range(total_number_edges):\n",
    "\n",
    "        node1 = edges[0][i]\n",
    "        node2 = edges[1][i]\n",
    "\n",
    "        # difference between node features\n",
    "        node_i_features = node_features[node1]  # [#features(charge, loc, vel), dim]\n",
    "        node_j_features = node_features[node2]  # [#features(charge, loc, vel), dim]\n",
    "        difference = node_i_features - node_j_features\n",
    "\n",
    "        # geom product between node features\n",
    "        geom_product = clifford_algebra.geometric_product(node_i_features, node_j_features)\n",
    "\n",
    "        # now just add the 2 to get the \"representation of the edge\"\n",
    "        # Stack all\n",
    "        edge_representation = torch.cat((difference, geom_product), dim=0)\n",
    "        edge_attributes.append(edge_representation)\n",
    "\n",
    "    edge_attributes = torch.stack(edge_attributes)\n",
    "    return edge_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3PsPP03ZtK3y",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.778101Z",
     "start_time": "2024-05-14T08:10:42.774379Z"
    }
   },
   "outputs": [],
   "source": [
    "def embed_nbody_graphs(batch):\n",
    "    loc, vel, edge_attr, charges, loc_end, edges = batch\n",
    "\n",
    "    batch_size, n_nodes, _ = loc.size()\n",
    "\n",
    "\n",
    "    # put the mean of the pointcloud on the origin (WHY?)\n",
    "    loc_mean = loc - loc.mean(dim=1, keepdim=True)     # [batch, nodes, dim]\n",
    "\n",
    "\n",
    "    # ALL THESE do [batch, nodes, dim] ->>> [batch * nodes, dim] BUT WHYYY\n",
    "    loc_mean = loc_mean.float().view(-1, *loc_mean.shape[2:])\n",
    "    loc = loc.float().view(-1, *loc.shape[2:])\n",
    "    vel = vel.float().view(-1, *vel.shape[2:])\n",
    "    edge_attr = edge_attr.float().view(-1, *edge_attr.shape[2:])\n",
    "    charges = charges.float().view(-1, *charges.shape[2:])\n",
    "    loc_end = loc_end.float().view(-1, *loc_end.shape[2:])\n",
    "\n",
    "    invariants = charges\n",
    "    invariants = clifford_algebra.embed(invariants, (0,))\n",
    "    charges_in_clifford = invariants\n",
    "\n",
    "    xv = torch.stack([loc_mean, vel], dim=1) # now of the shape [batch * nodes, 2 (because its loc mean as well as vel), dim]\n",
    "    covariants = clifford_algebra.embed(xv, (1, 2, 3))\n",
    "    pos_vel_in_clifford = covariants\n",
    "\n",
    "\n",
    "    # the [:, none] adds a dimension to invariants: [500, 8] to 500, 1, 8]) so they can be concatinated\n",
    "    nodes_in_clifford = torch.cat([invariants[:, None], covariants], dim=1) # [batch * nodes, #features(charge, loc, vel), dim]\n",
    "    # print('nodes_in_clifford: [batch * nodes, #features(charge, loc, vel), dim]', nodes_in_clifford.shape)\n",
    "\n",
    "    # till now: edges [batch, 2, n_nodes] so per batch, first row is starting nodes, second row is finishing nodes.\n",
    "    # Batch 1:  [[0, 1, 2, 3, 4],  # Start nodes\n",
    "    #            [1, 2, 3, 4, 0]]  # End nodes\n",
    "\n",
    "    # Batch 2:  [[0, 1, 2, 3, 4],  # Start nodes\n",
    "    #            [1, 2, 3, 4, 0]]  # End nodes\n",
    "\n",
    "    # Batch 3:  [[0, 1, 2, 3, 4],  # Start nodes\n",
    "    #            [1, 2, 3, 4, 0]]  # End nodes\n",
    "\n",
    "\n",
    "    # THEIR CODE, IDK IF NEEDED\n",
    "    batch_index = torch.arange(batch_size, device=loc_mean.device) # torch.arange(batch_size) generates a tensor from 0 to batch_size - 1, creating a sequence that represents each graph in the batch. If batch_size is 3, this tensor will be [0, 1, 2]\n",
    "    edges = edges + n_nodes * batch_index[:, None, None] # creates separate edge number for every graph. so if edge for graph 1 is between 3 and 4, graph 2 will be between 8 and 9 (if n_nodes = 5)\n",
    "    edges = tuple(edges.transpose(0, 1).flatten(1)) # where the first element of the tuple contains all start nodes and the second contains all end nodes for edges across the entire batch. ([edges*batch], [edges*batch])\n",
    "\n",
    "    extra_edge_attr_clifford = make_edge_attr(nodes_in_clifford, edges, batch_size) # [batch*edges, #numfeatures, difference + geomprod, dim]\n",
    "\n",
    "    orig_edge_attr_clifford = clifford_algebra.embed(edge_attr[..., None], (0,)) # now [batch * edges, 1, dim]\n",
    "\n",
    "    return nodes_in_clifford, extra_edge_attr_clifford, orig_edge_attr_clifford\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PiZr4WTX5_4y",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.781155Z",
     "start_time": "2024-05-14T08:10:42.778626Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_mock_batch(batch_size):\n",
    "    \"\"\"\n",
    "    Generate a mock batch of data with specified shapes.\n",
    "\n",
    "    Parameters:\n",
    "    - batch_size (int): The size of the batch to generate.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing tensors for loc_frame_0, vel_frame_0, edge_attr, charges, loc_frame_T, and edges.\n",
    "    \"\"\"\n",
    "    # Constants\n",
    "    n_nodes = 5  # Number of nodes\n",
    "    n_features = 3  # Number of spatial features (e.g., x, y, z)\n",
    "    n_edges = 20  # Number of edges\n",
    "    n_edge_features = 1  # Number of features per edge\n",
    "\n",
    "    # Generate data\n",
    "    loc_frame_0 = torch.rand(batch_size, n_nodes, n_features)\n",
    "    vel_frame_0 = torch.rand(batch_size, n_nodes, n_features)\n",
    "    edge_attr = torch.rand(batch_size, n_edges, n_edge_features)\n",
    "    charges = torch.rand(batch_size, n_nodes, 1)\n",
    "    loc_frame_T = torch.rand(batch_size, n_nodes, n_features)\n",
    "\n",
    "    # Generate edges indices\n",
    "    # For simplicity, assuming all batches share the same structure of graph\n",
    "    rows = torch.randint(0, n_nodes, (n_edges,))\n",
    "    cols = torch.randint(0, n_nodes, (n_edges,))\n",
    "    edges = torch.stack([rows, cols], dim=0).repeat(batch_size, 1, 1)  # Repeat the edge structure across the batch\n",
    "\n",
    "    return loc_frame_0, vel_frame_0, edge_attr, charges, loc_frame_T, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fnh-oBZBjPLh",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.785454Z",
     "start_time": "2024-05-14T08:10:42.781941Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example of using the function with a batch size of 69\n",
    "batch_size = 100\n",
    "data = generate_mock_batch(batch_size)\n",
    "# n_nodes = 5  # Number of nodes\n",
    "# n_features = 3  # Number of spatial features (e.g., x, y, z)\n",
    "# n_edges = 20  # Number of edges\n",
    "# n_edge_features = 1  # Number of features per edge\n",
    "\n",
    "# Print the shapes of each element in the data tuple\n",
    "data_shapes = [d.shape for d in data]\n",
    "# print(\"Shape of loc_frame_0:\", data_shapes[0])\n",
    "# print(\"Shape of vel_frame_0:\", data_shapes[1])\n",
    "# print(\"Shape of edge_attr:\", data_shapes[2])\n",
    "# print(\"Shape of charges:\", data_shapes[3])\n",
    "# print(\"Shape of loc_frame_T:\", data_shapes[4])\n",
    "# print(\"Shape of edges:\", data_shapes[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IosWbhgK69ET",
    "outputId": "ceb05131-7a01-4ea8-8fff-3a985872946b",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.861724Z",
     "start_time": "2024-05-14T08:10:42.786013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined: torch.Size([2500, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "components = embed_nbody_graphs(data)\n",
    "nodes_in_clifford, extra_edge_attr_clifford, orig_edge_attr_clifford = components\n",
    "edges_in_clifford = torch.cat((extra_edge_attr_clifford, orig_edge_attr_clifford), dim=1)\n",
    "\n",
    "# This MVLinear should be somewhere else! HOW DOES THIS WORK PRECICELY\n",
    "\n",
    "edge_to_node_shape = MVLinear(clifford_algebra, edges_in_clifford.shape[1] , nodes_in_clifford.shape[1], subspaces=True)\n",
    "\n",
    "fully_embedded_edges = edge_to_node_shape(edges_in_clifford)\n",
    "\n",
    "\n",
    "# Adding a binary feature\n",
    "# Nodes get a [1, 0] and edges get a [0, 1]\n",
    "node_marker = torch.zeros(500, 1, 8)\n",
    "edge_marker = torch.ones(2000, 1, 8)\n",
    "\n",
    "# Concatenate this new feature\n",
    "nodes_encoded = torch.cat((nodes_in_clifford, node_marker), dim=1)  # New shape [500, 4, 8]\n",
    "edges_encoded = torch.cat((fully_embedded_edges, edge_marker), dim=1)  # New shape [2000, 4, 8]\n",
    "\n",
    "# Reshape to split according to graphs\n",
    "nodes = nodes_encoded.view(100, 5, 4, 8)   # Shape [100, 5, 3, 9]\n",
    "edges = edges_encoded.view(100, 20, 4, 8)  # Shape [100, 20, 3, 9]\n",
    "\n",
    "# Initialize a list to hold the combined tensors for each graph\n",
    "combined = []\n",
    "\n",
    "# Concatenate nodes and edges for each graph\n",
    "for i in range(100):\n",
    "    combined_graph = torch.cat((nodes[i], edges[i]), dim=0)  # Shape [25, 4, 8]\n",
    "    combined.append(combined_graph)\n",
    "\n",
    "combined = torch.stack(combined, dim=0)  # Shape [100, 25, 4, 8]\n",
    "final_tensor = combined.view(2500, 4, 8)  # Shape [2500, 4, 8]\n",
    "\n",
    "print('combined:', final_tensor.shape)\n",
    "\n",
    "\n",
    "# print(final_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-C42MKe324X"
   },
   "source": [
    "code for learnable positional encodings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "q6dhu2Ew3XVv",
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.867380Z",
     "start_time": "2024-05-14T08:10:42.862497Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GeometricAlgebraAttention(nn.Module):\n",
    "    def __init__(self, algebra, features, heads=8):\n",
    "        super().__init__()\n",
    "        self.algebra = algebra\n",
    "        self.heads = heads\n",
    "        self.features_per_head = features // heads\n",
    "        \n",
    "        assert features % heads == 0, \"Features must be divisible by heads\"\n",
    "        \n",
    "        self.query = MVLinear(self.algebra, features, features)\n",
    "        self.key = MVLinear(self.algebra, features, features)\n",
    "        self.value = MVLinear(self.algebra, features, features)\n",
    "        \n",
    "        self.unifyheads = MVLinear(self.algebra, features, features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, f = x.size()\n",
    "        print(f\"Input size: {x.size()}\")\n",
    "\n",
    "        queries = self.query(x).view(b, t, self.heads, self.features_per_head)\n",
    "        print(f\"Queries size: {queries.size()}\")\n",
    "        keys = self.key(x).view(b, t, self.heads, self.features_per_head)\n",
    "        print(f\"Keys size: {keys.size()}\")\n",
    "        values = self.value(x).view(b, t, self.heads, self.features_per_head)\n",
    "        print(f\"Values size: {values.size()}\")\n",
    "        \n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        values = values.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        \n",
    "        scores = torch.matmul(queries, keys.transpose(1, 2)) / (self.features_per_head ** 0.5)\n",
    "        scores = F.softmax(scores, dim=2)\n",
    "        \n",
    "        combined = torch.matmul(scores, values)\n",
    "        combined = combined.view(b, self.heads, t, self.features_per_head).transpose(1, 2).contiguous()\n",
    "        combined = combined.view(b, t, f)\n",
    "        \n",
    "        return self.unifyheads(combined)\n",
    "\n",
    "class NBodyCGGNN(nn.Module):\n",
    "    def __init__(self, algebra, in_features, hidden_features, out_features, n_heads=8, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.algebra = algebra\n",
    "        self.embedding = MVLinear(self.algebra, in_features, hidden_features)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            GeometricAlgebraAttention(self.algebra, hidden_features, heads=n_heads)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.projection = MVLinear(self.algebra, hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return self.projection(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.872742Z",
     "start_time": "2024-05-14T08:10:42.868107Z"
    }
   },
   "outputs": [],
   "source": [
    "class GeometricAlgebraAttention(nn.Module):\n",
    "    def __init__(self, algebra, features, heads=8):\n",
    "        super().__init__()\n",
    "        self.algebra = algebra\n",
    "        self.heads = heads\n",
    "        self.features_per_head = features // heads\n",
    "        assert features % heads == 0, \"Features must be divisible by heads\"\n",
    "        \n",
    "        self.query = MVLinear(self.algebra, features, features)\n",
    "        self.key = MVLinear(self.algebra, features, features)\n",
    "        self.value = MVLinear(self.algebra, features, features)\n",
    "        \n",
    "        self.unifyheads = MVLinear(self.algebra, features, features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, f = x.size()\n",
    "        print(f\"Input size before MVLinear: {x.size()}\")  # Check input size\n",
    "\n",
    "        queries = self.query(x)\n",
    "        keys = self.key(x)\n",
    "        values = self.value(x)\n",
    "        print(f\"Output size from MVLinear (queries): {queries.size()}\")  # Check output size\n",
    "\n",
    "        queries = queries.view(b, t, self.heads, self.features_per_head)\n",
    "        keys = keys.view(b, t, self.heads, self.features_per_head)\n",
    "        values = values.view(b, t, self.heads, self.features_per_head)\n",
    "\n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        values = values.transpose(1, 2).contiguous().view(b * self.heads, t, self.features_per_head)\n",
    "        \n",
    "        scores = torch.matmul(queries, keys.transpose(1, 2)) / (self.features_per_head ** 0.5)\n",
    "        scores = F.softmax(scores, dim=2)\n",
    "        \n",
    "        combined = torch.matmul(scores, values)\n",
    "        combined = combined.view(b, self.heads, t, self.features_per_head).transpose(1, 2).contiguous()\n",
    "        combined = combined.view(b, t, f)\n",
    "        \n",
    "        return self.unifyheads(combined)\n",
    "        \n",
    "\n",
    "class NBodyCGGNN(nn.Module):\n",
    "    def __init__(self, algebra, in_features, hidden_features, out_features, n_heads=8, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.algebra = algebra\n",
    "        self.embedding = MVLinear(self.algebra, in_features, hidden_features)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            GeometricAlgebraAttention(self.algebra, hidden_features, heads=n_heads)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.projection = MVLinear(self.algebra, hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return self.projection(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:42.875071Z",
     "start_time": "2024-05-14T08:10:42.873661Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T08:11:51.437253Z",
     "start_time": "2024-05-14T08:11:04.604739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size before MVLinear: torch.Size([2500, 8, 8])\n",
      "Output size from MVLinear (queries): torch.Size([2500, 8, 8])\n",
      "Input size before MVLinear: torch.Size([2500, 8, 8])\n",
      "Output size from MVLinear (queries): torch.Size([2500, 8, 8])\n",
      "Input size before MVLinear: torch.Size([2500, 8, 8])\n",
      "Output size from MVLinear (queries): torch.Size([2500, 8, 8])\n",
      "torch.Size([2500, 1, 8])\n",
      "tensor([[[ 4.4574e-05,  5.6464e-03,  5.8109e-03,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 8.1802e-05,  3.8217e-03,  5.3485e-03,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 8.8158e-05,  4.3965e-03,  4.6910e-03,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.2115e-05, -1.6034e-03, -1.9427e-03,  ..., -9.9428e-04,\n",
      "          -1.0125e-03, -2.0850e-02]],\n",
      "\n",
      "        [[ 1.3147e-04, -2.5135e-03, -2.7101e-03,  ..., -9.2114e-04,\n",
      "          -9.2582e-04, -2.0850e-02]],\n",
      "\n",
      "        [[ 6.7645e-05, -1.9510e-03, -2.0400e-03,  ..., -1.0218e-03,\n",
      "          -9.6158e-04, -2.0850e-02]]], grad_fn=<AsStridedBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = NBodyCGGNN(clifford_algebra, in_features=4, hidden_features=8, out_features=1)  # Example with hidden_features=8\n",
    "final_tensor_reshaped = final_tensor.view(-1, 4, 8)  # Ensure it matches the total elements\n",
    "output = model(final_tensor_reshaped)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T08:10:43.258279Z",
     "start_time": "2024-05-14T08:10:42.899365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size before MVLinear: torch.Size([2500, 32, 8])\n",
      "Output size from MVLinear (queries): torch.Size([2500, 32, 8])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2500, 32, 8, 4]' is invalid for input of size 640000",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m NBodyCGGNN(clifford_algebra, in_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, hidden_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, out_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# Changed hidden_features to 32\u001B[39;00m\n\u001B[1;32m      3\u001B[0m final_tensor_reshaped \u001B[38;5;241m=\u001B[39m final_tensor\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m8\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m output \u001B[38;5;241m=\u001B[39m model(final_tensor_reshaped)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(output\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(output)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[21], line 60\u001B[0m, in \u001B[0;36mNBodyCGGNN.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     57\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding(x)\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 60\u001B[0m     x \u001B[38;5;241m=\u001B[39m layer(x)\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprojection(x)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[21], line 24\u001B[0m, in \u001B[0;36mGeometricAlgebraAttention.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     21\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalue(x)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOutput size from MVLinear (queries): \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mqueries\u001B[38;5;241m.\u001B[39msize()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# Check output size\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m queries \u001B[38;5;241m=\u001B[39m queries\u001B[38;5;241m.\u001B[39mview(b, t, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures_per_head)\n\u001B[1;32m     25\u001B[0m keys \u001B[38;5;241m=\u001B[39m keys\u001B[38;5;241m.\u001B[39mview(b, t, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures_per_head)\n\u001B[1;32m     26\u001B[0m values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mview(b, t, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures_per_head)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: shape '[2500, 32, 8, 4]' is invalid for input of size 640000"
     ]
    }
   ],
   "source": [
    "clifford_algebra = CliffordAlgebra((1.0, 1.0, 1.0))\n",
    "model = NBodyCGGNN(clifford_algebra, in_features=4, hidden_features=32, out_features=1)  # Changed hidden_features to 32\n",
    "final_tensor_reshaped = final_tensor.view(-1, 4, 8)\n",
    "output = model(final_tensor_reshaped)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = NBodyCGGNN(clifford_algebra, in_features=4, hidden_features=8, out_features=1)  # Example with hidden_features=8\n",
    "final_tensor_reshaped = final_tensor.view(-1, 4, 8)  # Ensure it matches the total elements\n",
    "output = model(final_tensor_reshaped)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
